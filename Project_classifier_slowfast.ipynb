{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:/Jester/Jester/20bn-jester-v1/*'\n",
    "num_classes = 27\n",
    "num_worker = 0\n",
    "batch_size = 128\n",
    "scales = [1, 1/2**(1/4), 1/2**(1/2)]\n",
    "sample_size = (96,160)\n",
    "sample_duration = 16\n",
    "rgb_mean = (0.485, 0.456, 0.406)\n",
    "rgb_std = (0.229, 0.224, 0.225)\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortKeyFunc(s):\n",
    "    return int(os.path.basename(s)[:])\n",
    "\n",
    "def load_all_path(root):\n",
    "    video_dictionary = glob.glob(root)\n",
    "    video_dictionary.sort(key=sortKeyFunc)\n",
    "    all_path = []\n",
    "    for video_path in video_dictionary:\n",
    "        file_list = sorted(glob.glob(video_path + '/*'))\n",
    "        all_path.append(file_list)\n",
    "    return all_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = load_all_path(root)\n",
    "labels = np.genfromtxt('D:/Jester/jester-v1-labels.csv', delimiter=',', dtype=np.str)\n",
    "labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalCrop(object):\n",
    "    \"\"\"Temporally crop the given frame indices at a random location or at the center location.\n",
    "        size (int): Desired output size of the crop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, mode):\n",
    "        self.size = size*2\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            paths (list): paths to be cropped.\n",
    "        Returns:\n",
    "            list: Cropped paths.\n",
    "        \"\"\"\n",
    "        num_frames = len(path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            if num_frames < self.size:\n",
    "                num_loops = self.size//num_frames\n",
    "                delta = self.size - num_frames*num_loops\n",
    "                new_path = path*num_loops + path[0:delta]\n",
    "            else:\n",
    "                begin_index = random.randint(0, num_frames - self.size)\n",
    "                end_index = begin_index + self.size\n",
    "                new_path = path[begin_index:end_index]\n",
    "        else:\n",
    "            if num_frames < self.size:\n",
    "                num_loops = self.size//num_frames\n",
    "                delta = self.size - num_frames*num_loops\n",
    "                new_path = path*num_loops + path[0:delta]\n",
    "            else:\n",
    "                begin_index = (num_frames - self.size)//2\n",
    "                end_index = begin_index + self.size\n",
    "                new_path = path[begin_index:end_index]\n",
    "                \n",
    "        new_path = new_path[0:self.size]\n",
    "        return new_path\n",
    "\n",
    "class MultiScaleRandomCrop(object):\n",
    "\n",
    "    def __init__(self, scales, size, interpolation=Image.BILINEAR):\n",
    "        self.scales = scales\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation       \n",
    "\n",
    "    def get_random_param(self):\n",
    "        self.scale = self.scales[random.randint(0, len(self.scales) - 1)]\n",
    "        self.topleft_x = random.random()\n",
    "        self.topleft_y = random.random()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image_width, image_height = img.size\n",
    "        out_height, out_width = self.size\n",
    "        crop_height = out_height*self.scale\n",
    "        crop_width = out_width*self.scale\n",
    "\n",
    "        topleft_x = self.topleft_x * (image_width - crop_width)\n",
    "        topleft_y = self.topleft_y * (image_height - crop_height)\n",
    "        bottomright_x = topleft_x + crop_width\n",
    "        bottomright_y = topleft_y + crop_height\n",
    "\n",
    "        img = img.crop((topleft_x, topleft_y, bottomright_x, bottomright_y))\n",
    "        img = img.resize((out_width, out_height), self.interpolation)\n",
    "\n",
    "        return img\n",
    "    \n",
    "class RandomCrop(object):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.size = size  \n",
    "\n",
    "    def get_random_param(self):\n",
    "        self.topleft_x = random.random()\n",
    "        self.topleft_y = random.random()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image_width, image_height = img.size\n",
    "        out_height, out_width = self.size\n",
    "\n",
    "        topleft_x = self.topleft_x * (image_width - out_width)\n",
    "        topleft_y = self.topleft_y * (image_height - out_height)\n",
    "        bottomright_x = topleft_x + out_width\n",
    "        bottomright_y = topleft_y + out_height\n",
    "\n",
    "        img = img.crop((topleft_x, topleft_y, bottomright_x, bottomright_y))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(paths, mode):\n",
    "    all_image = []\n",
    "    temporal_transform = TemporalCrop(sample_duration, mode)\n",
    "    if mode == 'train':\n",
    "        RandomCrops = MultiScaleRandomCrop(scales, sample_size)\n",
    "        RandomCrops.get_random_param()\n",
    "        spatial_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            RandomCrops,\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(rgb_mean, rgb_std)\n",
    "        ])\n",
    "    else:\n",
    "        spatial_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "#             transforms.Resize(sample_size),\n",
    "            transforms.CenterCrop(sample_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(rgb_mean, rgb_std)\n",
    "        ])\n",
    "                \n",
    "    new_paths = temporal_transform(paths)\n",
    "    width = cv2.imread(new_paths[0]).shape[1]\n",
    "    if width != 176:\n",
    "        padding = np.zeros((100,(176-width)//2,3), dtype=np.uint8)\n",
    "        for path in new_paths:\n",
    "            image = cv2.imread(path)\n",
    "            image = np.concatenate([padding, image, padding], axis=1)\n",
    "            image = spatial_transform(image)\n",
    "            all_image.append(image)\n",
    "    else:\n",
    "        for path in new_paths:\n",
    "            image = cv2.imread(path)\n",
    "            image = spatial_transform(image)\n",
    "            all_image.append(image)\n",
    "            \n",
    "    video = np.stack(all_image).transpose(1,0,2,3)\n",
    "#     print(video.shape)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, all_path, x, y, mode):\n",
    "        self.length = len(x)\n",
    "        self.all_path = all_path\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.length)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train' or self.mode == 'valid':\n",
    "            x = read_video(self.all_path[int(self.x[index,0])-1], self.mode)\n",
    "            y = int(np.argwhere(self.y == self.x[index,1]))\n",
    "            return torch.from_numpy(x), torch.tensor(y)\n",
    "        else:\n",
    "            x = read_video(self.all_path[int(self.x[index])-1], self.mode)\n",
    "            return torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt('D:/Jester/jester-v1-train.csv', delimiter=',', dtype=np.str)    \n",
    "train_data = Dataset(all_path, train, labels, 'train')\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.genfromtxt('D:/Jester/jester-v1-validation.csv', delimiter=',', dtype=np.str)\n",
    "valid_data = Dataset(all_path, valid, labels, 'valid')\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.genfromtxt('D:/Jester/jester-v1-test.csv', delimiter=',', dtype=np.str)\n",
    "test_data = Dataset(all_path, test, labels, 'test')\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowFastFusion(nn.Module):\n",
    "    def __init__(self, dim_in, fusion_conv_channel_ratio, fusion_kernel, alpha):\n",
    "        super(SlowFastFusion, self).__init__()\n",
    "        self.conv_f2s = nn.Sequential(\n",
    "            nn.Conv3d(dim_in, dim_in * fusion_conv_channel_ratio, kernel_size=(fusion_kernel, 1, 1),\n",
    "                stride=(alpha, 1, 1), padding=(fusion_kernel // 2, 0, 0), bias=False),\n",
    "            nn.BatchNorm3d(num_features=dim_in * fusion_conv_channel_ratio),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x_s = x1\n",
    "        x_f = x2\n",
    "        fuse = self.conv_f2s(x_f)\n",
    "        x_s_fuse = torch.cat([x_s, fuse], 1)\n",
    "        return x_s_fuse, x_f\n",
    "    \n",
    "class SlowFastBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, cardinality=32, width=4, stride=1):\n",
    "        super(SlowFastBlock1, self).__init__()\n",
    "        channels = cardinality*width\n",
    "        out_channels = 2*channels\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm3d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(channels, channels, kernel_size=(1,3,3), stride=stride, padding=(0,1,1), groups=cardinality, bias=False),\n",
    "            nn.BatchNorm3d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "        )\n",
    "        \n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.prelu(out)\n",
    "        return out\n",
    "\n",
    "class SlowFastBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, cardinality=32, width=4, stride=1):\n",
    "        super(SlowFastBlock2, self).__init__()\n",
    "        channels = cardinality*width\n",
    "        out_channels = 2*channels\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, channels, kernel_size=(3,1,1), padding=(1,0,0), bias=False),\n",
    "            nn.BatchNorm3d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(channels, channels, kernel_size=(1,3,3), stride=stride, padding=(0,1,1), groups=cardinality, bias=False),\n",
    "            nn.BatchNorm3d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "        )\n",
    "        \n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.prelu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowFastNet(nn.Module):\n",
    "    def __init__(self, block1, block2, num_blocks, cardinality=32, width=4, num_class=27):\n",
    "        super(SlowFastNet, self).__init__()\n",
    "        self.cardinality_slow = cardinality\n",
    "        self.cardinality_fast = cardinality//8\n",
    "        self.width_slow = width\n",
    "        self.width_fast = width\n",
    "        self.slow_in_channels = 64\n",
    "        self.fast_in_channels = 8\n",
    "        \n",
    "        self.slownet_head = nn.Sequential(\n",
    "            nn.Conv3d(3, 64, kernel_size=(1,7,7), stride=(1,2,2), padding=(0,3,3), bias=False),\n",
    "            nn.MaxPool3d(kernel_size=(1,3,3), stride=(1,2,2), padding=(0,1,1)))\n",
    "        self.slownet_res2 = self.stack_blocks_slow(block1, num_blocks[0], stride=1)\n",
    "        self.slownet_res3 = self.stack_blocks_slow(block1, num_blocks[1], stride=2)\n",
    "        self.slownet_res4 = self.stack_blocks_slow(block2, num_blocks[2], stride=2)\n",
    "        self.slownet_res5 = self.stack_blocks_slow(block2, num_blocks[3], stride=2)\n",
    "        \n",
    "        self.fastnet_head = nn.Sequential(\n",
    "            nn.Conv3d(3, 8, kernel_size=(5,7,7), stride=(1,2,2), padding=(2,3,3), bias=False),\n",
    "            nn.MaxPool3d(kernel_size=(1,3,3), stride=(1,2,2), padding=(0,1,1)))\n",
    "\n",
    "        self.fastnet_res2 = self.stack_blocks_fast(block2, num_blocks[0], stride=1)\n",
    "        self.fastnet_res3 = self.stack_blocks_fast(block2, num_blocks[1], stride=2)\n",
    "        self.fastnet_res4 = self.stack_blocks_fast(block2, num_blocks[2], stride=2)\n",
    "        self.fastnet_res5 = self.stack_blocks_fast(block2, num_blocks[3], stride=2)\n",
    "        \n",
    "        self.fuse1 = SlowFastFusion(8,2,5,4)\n",
    "        self.fuse2 = SlowFastFusion(32,2,5,4)\n",
    "        self.fuse3 = SlowFastFusion(64,2,5,4)\n",
    "        self.fuse4 = SlowFastFusion(128,2,5,4)\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool3d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.out = nn.Linear(self.slow_in_channels + self.fast_in_channels, num_class)\n",
    "        \n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(layer, nn.BatchNorm3d):\n",
    "                nn.init.constant_(layer.weight, val=1.0)\n",
    "                nn.init.constant_(layer.bias, val=0.0)\n",
    "            elif isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.constant_(layer.bias, val=0.0)\n",
    "                \n",
    "    def stack_blocks_slow(self, block, num_blocks, stride):\n",
    "        strides = [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        layers.append(block(int(self.slow_in_channels*1.25), self.cardinality_slow, self.width_slow, stride))\n",
    "        for stride in strides:\n",
    "            self.slow_in_channels = 2*self.cardinality_slow*self.width_slow\n",
    "            layers.append(block(self.slow_in_channels, self.cardinality_slow, self.width_slow, stride))\n",
    "        self.width_slow *= 2\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def stack_blocks_fast(self, block, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.fast_in_channels, self.cardinality_fast, self.width_fast, stride))\n",
    "            self.fast_in_channels = 2*self.cardinality_fast*self.width_fast\n",
    "        self.width_fast *= 2\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_fast = x[:,:,0:32,:,:]\n",
    "        x_slow = x[:,:,2:34:4,:,:]\n",
    "        \n",
    "        x_fast = self.fastnet_head(x_fast)\n",
    "        x_slow = self.slownet_head(x_slow)\n",
    "        x_slow, x_fast = self.fuse1(x_slow, x_fast)\n",
    "        \n",
    "        x_fast = self.fastnet_res2(x_fast)\n",
    "        x_slow = self.slownet_res2(x_slow)\n",
    "        x_slow, x_fast = self.fuse2(x_slow, x_fast)\n",
    "        \n",
    "        x_fast = self.fastnet_res3(x_fast)\n",
    "        x_slow = self.slownet_res3(x_slow)\n",
    "        x_slow, x_fast = self.fuse3(x_slow, x_fast)\n",
    "        \n",
    "        x_fast = self.fastnet_res4(x_fast)\n",
    "        x_slow = self.slownet_res4(x_slow)\n",
    "        x_slow, x_fast = self.fuse4(x_slow, x_fast)\n",
    "        \n",
    "        x_fast = self.fastnet_res5(x_fast)\n",
    "        x_slow = self.slownet_res5(x_slow)\n",
    "        \n",
    "        x_fast = self.pooling(x_fast)\n",
    "        x_slow = self.pooling(x_slow)\n",
    "        \n",
    "        x = torch.cat([x_slow.view(x_slow.size(0),x_slow.size(1)), x_fast.view(x_fast.size(0), x_fast.size(1))], dim=1)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        print(i, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    print('Training Loss: ', running_loss)\n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        \n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, labels).detach()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Validation Loss: ', running_loss)\n",
    "        print('Validation Accuracy: ', acc, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SlowFastNet(SlowFastBlock1, SlowFastBlock2, [3,4,6,3], cardinality=32, width=4, num_class=num_classes)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load('project_classifier_slowfast9295.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor=0.1, patience=2)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_epochs = 100\n",
    "# Train_loss = []\n",
    "# Train_acc = []\n",
    "# Valid_loss = []\n",
    "# Valid_acc = []\n",
    "# num_no_improve = 0\n",
    "# for i in range(n_epochs):\n",
    "#     train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "#     valid_loss, valid_acc = test_model(model, valid_loader, criterion)\n",
    "#     Train_acc.append(train_acc)\n",
    "#     Train_loss.append(train_loss)\n",
    "#     Valid_loss.append(valid_loss)\n",
    "#     scheduler.step(valid_loss)\n",
    "#     print('='*40)\n",
    "\n",
    "#     if i == 0:\n",
    "#         torch.save(model.state_dict(), 'project_classifier_slowfast.pth')\n",
    "#     else:\n",
    "#         if valid_acc > max(Valid_acc):\n",
    "#             torch.save(model.state_dict(), 'project_classifier_slowfast.pth')\n",
    "#             num_no_improve = 0\n",
    "#         else:\n",
    "#             num_no_improve += 1\n",
    "#     Valid_acc.append(valid_acc)\n",
    "    \n",
    "#     training_loss = np.array(Train_loss).reshape(-1,1)\n",
    "#     training_acc = np.array(Train_acc).reshape(-1,1)\n",
    "#     validation_loss = np.array(Valid_loss).reshape(-1,1)\n",
    "#     validation_acc = np.array(Valid_acc).reshape(-1,1)\n",
    "#     result = np.concatenate([training_loss, training_acc, validation_loss, validation_acc], axis=1)\n",
    "#     np.savetxt('result_project_classifier_slowfast.csv', result, delimiter=',', fmt='%1.5f', header='training_loss,training_acc,validation_loss,validation_acc', comments='')\n",
    "    \n",
    "#     if num_no_improve >= 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = []\n",
    "        total_duration = 0\n",
    "        labels = np.genfromtxt('D:/Jester/jester-v1-labels.csv', delimiter=',', dtype=np.str)\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            start = time.time()\n",
    "            inputs = data.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            end = time.time()\n",
    "            \n",
    "            for n in range(inputs.size(0)):\n",
    "                prediction = labels[predicted[n]]\n",
    "                output.append(prediction)\n",
    "            \n",
    "            duration = end - start\n",
    "            total_duration += duration\n",
    "            print(i, duration)\n",
    "        \n",
    "        index = np.genfromtxt('D:/Jester/jester-v1-test.csv', delimiter=',', dtype=np.str).reshape(-1,1)\n",
    "        Predicted = np.array(output, dtype=np.str).reshape(-1,1)\n",
    "        submission = np.concatenate((index, Predicted), axis=1)\n",
    "        \n",
    "    np.savetxt('predict.csv', Predicted, delimiter=',', fmt='%s')\n",
    "    average_duration = total_duration/len(test_loader.dataset)\n",
    "    print(average_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
