{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '20bn-jester-v1/*'\n",
    "num_classes = 2\n",
    "num_worker = 8\n",
    "batch_size = 128\n",
    "scales = [1, 1/2**(1/4), 1/2**(1/2)]\n",
    "sample_size = (96,160)\n",
    "sample_duration = 16\n",
    "rgb_mean = (0.485, 0.456, 0.406)\n",
    "rgb_std = (0.229, 0.224, 0.225)\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortKeyFunc(s):\n",
    "    return int(os.path.basename(s)[:])\n",
    "\n",
    "def load_all_path(root):\n",
    "    video_dictionary = glob.glob(root)\n",
    "    video_dictionary.sort(key=sortKeyFunc)\n",
    "    all_path = []\n",
    "    for video_path in video_dictionary:\n",
    "        file_list = sorted(glob.glob(video_path + '/*'))\n",
    "        all_path.append(file_list)\n",
    "    return all_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = load_all_path(root)\n",
    "labels = np.genfromtxt('jester-v1-labels.csv', delimiter=',', dtype=np.str)\n",
    "labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalCrop(object):\n",
    "    \"\"\"Temporally crop the given frame indices at a random location or at the center location.\n",
    "        size (int): Desired output size of the crop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, mode):\n",
    "        self.size = size*2\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            paths (list): paths to be cropped.\n",
    "        Returns:\n",
    "            list: Cropped paths.\n",
    "        \"\"\"\n",
    "        num_frames = len(path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            if num_frames < self.size:\n",
    "                num_loops = self.size//num_frames\n",
    "                delta = self.size - num_frames*num_loops\n",
    "                new_path = path*num_loops + path[0:delta]\n",
    "            else:\n",
    "                begin_index = random.randint(0, num_frames - self.size)\n",
    "                end_index = begin_index + self.size\n",
    "                new_path = path[begin_index:end_index]\n",
    "        else:\n",
    "            if num_frames < self.size:\n",
    "                num_loops = self.size//num_frames\n",
    "                delta = self.size - num_frames*num_loops\n",
    "                new_path = path*num_loops + path[0:delta]\n",
    "            else:\n",
    "                begin_index = (num_frames - self.size)//2\n",
    "                end_index = begin_index + self.size\n",
    "                new_path = path[begin_index:end_index]\n",
    "                \n",
    "        new_path = new_path[0:self.size:2]\n",
    "        return new_path\n",
    "\n",
    "    \n",
    "class MultiScaleRandomCrop(object):\n",
    "\n",
    "    def __init__(self, scales, size, interpolation=Image.BILINEAR):\n",
    "        self.scales = scales\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation       \n",
    "\n",
    "    def get_random_param(self):\n",
    "        self.scale = self.scales[random.randint(0, len(self.scales) - 1)]\n",
    "        self.topleft_x = random.random()\n",
    "        self.topleft_y = random.random()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image_width, image_height = img.size\n",
    "        out_height, out_width = self.size\n",
    "        crop_height = out_height*self.scale\n",
    "        crop_width = out_width*self.scale\n",
    "\n",
    "        topleft_x = self.topleft_x * (image_width - crop_width)\n",
    "        topleft_y = self.topleft_y * (image_height - crop_height)\n",
    "        bottomright_x = topleft_x + crop_width\n",
    "        bottomright_y = topleft_y + crop_height\n",
    "\n",
    "        img = img.crop((topleft_x, topleft_y, bottomright_x, bottomright_y))\n",
    "        img = img.resize((out_width, out_height), self.interpolation)\n",
    "\n",
    "        return img\n",
    "    \n",
    "class RandomCrop(object):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.size = size  \n",
    "\n",
    "    def get_random_param(self):\n",
    "        self.topleft_x = random.random()\n",
    "        self.topleft_y = random.random()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        image_width, image_height = img.size\n",
    "        out_height, out_width = self.size\n",
    "\n",
    "        topleft_x = self.topleft_x * (image_width - out_width)\n",
    "        topleft_y = self.topleft_y * (image_height - out_height)\n",
    "        bottomright_x = topleft_x + out_width\n",
    "        bottomright_y = topleft_y + out_height\n",
    "\n",
    "        img = img.crop((topleft_x, topleft_y, bottomright_x, bottomright_y))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(paths, mode):\n",
    "    all_image = []\n",
    "    temporal_transform = TemporalCrop(sample_duration, mode)\n",
    "    if mode == 'train':\n",
    "        RandomCrop = MultiScaleRandomCrop(scales, sample_size)\n",
    "        RandomCrop.get_random_param()\n",
    "        spatial_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomCrop((96,160)),\n",
    "            RandomCrop,\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(rgb_mean, rgb_std)\n",
    "        ])\n",
    "    else:\n",
    "        spatial_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "#             transforms.Resize(sample_size),\n",
    "            transforms.CenterCrop((96,160)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(rgb_mean, rgb_std)\n",
    "        ])\n",
    "                \n",
    "    new_paths = temporal_transform(paths)\n",
    "    width = cv2.imread(new_paths[0]).shape[1]\n",
    "    if width != 176:\n",
    "        padding = np.zeros((100,(176-width)//2,3), dtype=np.uint8)\n",
    "        for path in new_paths:\n",
    "            image = cv2.imread(path)\n",
    "            image = np.concatenate([padding, image, padding], axis=1)\n",
    "            image = spatial_transform(image)\n",
    "            all_image.append(image)\n",
    "    else:\n",
    "        for path in new_paths:\n",
    "            image = cv2.imread(path)\n",
    "            image = spatial_transform(image)\n",
    "            all_image.append(image)\n",
    "            \n",
    "    video = np.stack(all_image).transpose(1,0,2,3)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, all_path, x, y, mode):\n",
    "        self.length = len(x)\n",
    "        self.all_path = all_path\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.length)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train' or self.mode == 'valid':\n",
    "            x = read_video(self.all_path[int(self.x[index,0])-1], self.mode)\n",
    "            y = int(np.argwhere(self.y == self.x[index,1]))\n",
    "            if y == len(self.y)-2:\n",
    "                y_binary = 0\n",
    "            else:\n",
    "                y_binary = 1 \n",
    "            return torch.from_numpy(x), torch.tensor(y_binary)\n",
    "        else:\n",
    "            x = read_video(self.all_path[int(self.x[index])-1], self.mode)\n",
    "            return torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt('jester-v1-train.csv', delimiter=',', dtype=np.str)    \n",
    "train_data = Dataset(all_path, train, labels, 'train')\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.genfromtxt('jester-v1-validation.csv', delimiter=',', dtype=np.str)\n",
    "valid_data = Dataset(all_path, valid, labels, 'valid')\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.genfromtxt('jester-v1-test.csv', delimiter=',', dtype=np.str)\n",
    "test_data = Dataset(all_path, test, labels, 'test')\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_worker, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, (data, target) in enumerate(train_loader):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "        )\n",
    "        \n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels),\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.prelu(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_class):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "\n",
    "        self.feature_detector = nn.Sequential(\n",
    "            nn.Conv3d(3, 16, kernel_size=(3,7,7), stride=(1,2,2), padding=(1,3,3), bias=False),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2, padding=1),\n",
    "            self.stack_blocks(block, num_blocks[0], stride=1),\n",
    "            self.stack_blocks(block, num_blocks[1], stride=2),\n",
    "            self.stack_blocks(block, num_blocks[2], stride=2),\n",
    "            self.stack_blocks(block, num_blocks[3], stride=2),\n",
    "            nn.AvgPool3d((1,3,5)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(256,num_class)\n",
    "        \n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(layer, nn.BatchNorm3d):\n",
    "                nn.init.constant_(layer.weight, val=1.0)\n",
    "                nn.init.constant_(layer.bias, val=0.0)\n",
    "            elif isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.constant_(layer.bias, val=0.0)\n",
    "                \n",
    "    def stack_blocks(self, block, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, self.in_channels*2, stride))\n",
    "            self.in_channels *= 2\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feature_detector(x)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        print(i, loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    print('Training Loss: ', running_loss)\n",
    "    print('Training Accuracy: ', acc, '%')\n",
    "    return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        wrong = 0\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "#             for n in range(inputs.size(0)):\n",
    "#                 if predicted[n] != labels[n]:\n",
    "#                     print('Prediction: ', predicted[n], '///Groundtruth: ', labels[n])\n",
    "#                     if predicted[n] == 1:\n",
    "#                         wrong += 1\n",
    "#             print(i, wrong)\n",
    "\n",
    "            loss = criterion(outputs, labels).detach()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Validation Loss: ', running_loss)\n",
    "        print('Validation Accuracy: ', acc, '%')\n",
    "        return running_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.5.0', 'resnext50_32x4d', pretrained=True)\n",
    "model = ResNet(BasicBlock, [1,1,1,1], num_class=num_classes)\n",
    "model.load_state_dict(torch.load('project_detector9600.pth'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor=0.1, patience=2)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "Train_loss = []\n",
    "Train_acc = []\n",
    "Valid_loss = []\n",
    "Valid_acc = []\n",
    "num_no_improve = 0\n",
    "for i in range(n_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    valid_loss, valid_acc = test_model(model, valid_loader, criterion)\n",
    "    Train_acc.append(train_acc)\n",
    "    Train_loss.append(train_loss)\n",
    "    Valid_loss.append(valid_loss)\n",
    "    scheduler.step(valid_loss)\n",
    "    print('='*40)\n",
    "\n",
    "    if i == 0:\n",
    "        torch.save(model.state_dict(), 'project_detector.pth')\n",
    "    else:\n",
    "        if valid_acc > max(Valid_acc):\n",
    "            torch.save(model.state_dict(), 'project_detector.pth')\n",
    "            num_no_improve = 0\n",
    "        else:\n",
    "            num_no_improve += 1\n",
    "    Valid_acc.append(valid_acc)\n",
    "    \n",
    "    training_loss = np.array(Train_loss).reshape(-1,1)\n",
    "    training_acc = np.array(Train_acc).reshape(-1,1)\n",
    "    validation_loss = np.array(Valid_loss).reshape(-1,1)\n",
    "    validation_acc = np.array(Valid_acc).reshape(-1,1)\n",
    "    result = np.concatenate([training_loss, training_acc, validation_loss, validation_acc], axis=1)\n",
    "    np.savetxt('result_project.csv', result, delimiter=',', fmt='%1.5f', header='training_loss,training_acc,validation_loss,validation_acc', comments='')\n",
    "    \n",
    "    if num_no_improve >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=momentum, weight_decay=weight_decay, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model(model, valid_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
